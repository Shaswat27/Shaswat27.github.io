<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0" />

    <!--Description-->
    
        <meta name="description" content="Personal blog and porfolio page">
    

    <!--Author-->
    
        <meta name="author" content="Shaswat Datta">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Lane Navigation"/>
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="Shaswat Datta"/>

    <!--Page Cover-->
    
        <meta property="og:image" content="undefined"/>
    

    <!-- Title -->
    
    <title>Lane Navigation - Shaswat Datta</title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/reset.css">
    <link rel="stylesheet" href="/css/main.css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-83741901-1', 'auto');
        ga('send', 'pageview');

    </script>



</head>

<body>

<!-- Menu -->
<!-- Navigation -->
<header>
    <div class="logo">
        <a href="/">Shaswat Datta</a>
    </div><!-- end logo -->

    <div id="menu_icon"></div>
    <nav>
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/archives">Archives</a>
            </li>
            
            <li>
                <a href="/about">About</a>
            </li>
            
        </ul>
    </nav><!-- end navigation menu -->

    <div class="footer clearfix">
        <ul class="social clearfix">
            
            
                <li><a href="https://www.facebook.com/shaswat27" class="fb" target="_blank" data-title="Facebook"></a></li>
            
            
            
                <li><a href="https://in.linkedin.com/in/shaswat-datta-86812075" class="google" target="_blank" data-title="LinkedIn"></a></li>
            
            
                <li><a href="mailto:shaswat.datta@gmail.com" class="dribble" target="_blank" data-title="Email"></a></li>
            
            
                <li><a href="https://www.github.com/shaswat27" class="rss" target="_blank" data-title="Github"></a></li>
            
        </ul><!-- end social -->

        <div class="rights">
            <p></p>
            <p></p>
            <p>Copyright © Shaswat Datta.</p>
        </div><!-- end rights -->
    </div ><!-- end footer -->
</header><!-- end header -->


<!-- Main Content -->
<section class="main clearfix">

    <section class="top" style="background: url('/images/LaneDet1.jpg');">
        <div class="wrapper content_header clearfix">
            

<div class="work_nav">

    <ul class="btn clearfix">
        
        <li><a href="/2016/10/20/Music-Harmonization/" class="previous" data-title="Music Harmonization"></a></li>
        
        <li><a href="/" class="grid" data-title="Portfolio"></a></li>
        
        <li><a class="next disabled"></a></li>
        
    </ul>

</div><!-- end work_nav -->
            <h1 class="title">Lane Navigation</h1>
        </div>
    </section><!-- end top -->

    <section class="wrapper">
        <div class="content">

            <!-- Gallery -->
            

            <!-- Content -->
            <p>Today, Driver Assistance Systems have made significant progress and several new algorithms have been designed to improve the understanding of environment surrounding the vehicle. Lane detection is one of the key issues of environment understanding. The problem is well-explored with existing approaches using varied sensors namely LIDAR (Light Detection and Ranging), radar and camera. </p>
<p>For the annual <a href="http://www.igvc.org/" target="_blank" rel="external">Intelligent Ground Vehicle Competition</a> (IGVC) lane detection is to be done on <em>grass</em> and the narrower lanes (as compared to roads) present new challenges such as the case of only a single lane remaining visible. For this year’s IGVC we had implemented a support vector machine (SVM) model to detect the lanes.</p>
<h3 id="The-SVM-Model"><a href="#The-SVM-Model" class="headerlink" title="The SVM Model"></a>The SVM Model</h3><p>The approach followed by us at the <a href="http://agv-iit-kgp.github.io/" target="_blank" rel="external">Autonomous Ground Vehicle</a> research group had been to train an SVM on a captured image by manually annotating lane and non-lane points and using that model to detect the lanes in the camera feed afterward as described below.</p>
<p>The grassy portions of the image were removed with the SVM (Support Vector Machine)<br>classifier where features for learning were taken as a kernel of an 8×8 ROI of the image. This kernel was classified as grass or non-grass type using a polynomial SVM classifier. The classifier was unable to generate satisfactory results due to the shadows which perturb the HSV values of the regions. Hence, a shadow removal technique was used. To that end, the image was first converted to the YCrCb color space. Then, all the pixels with intensity less than 1.5 times the standard deviation of Y channel were classified as shadow pixels and the image was converted into binary. Curves were generated by the classifier based on results over the shadow removed images. Although this was prone to false positives, most of the lanes were classified as nongrass. Also, grass offers a more uniform patch as compared to lanes as the lane portions in the image vary in brightness and lighting conditions. Lanes also exhibit non-uniform thickness. Hence, both the thresholding and Hough line method would still output false lanes. This would, even more, be the case in thresholding, as it is very difficult to find fine threshold values. So, Random Sample Consensus (RANSAC) was incorporated to detect lanes. On rigorous testing, RANSAC was found to be a reliable technique for curve-fitting. Finally, the image was transformed to a top down view by using an inverse perspective transform (IPT).</p>
<p>This classifier did give decent results, the problems, however, were plenty: the shadow removal didn’t work well, the classifier required a large dataset which we didn’t have and the effort required to manually annotate the image before each run (due to varying lighting conditions).</p>
<h3 id="Blind-Colour-Decomposition-Model"><a href="#Blind-Colour-Decomposition-Model" class="headerlink" title="Blind Colour Decomposition Model"></a>Blind Colour Decomposition Model</h3><p>A final year student - Arna Ghosh had worked with the <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6410037" target="_blank" rel="external">blind color decomposition</a> method (BCD) to analyze histological images for his internship. Though this was used for analyzing stains in microscope images, we thought this could potentially have applications in lane detection as well. So, I and Arna set forth to implement the same. </p>
<p>The method we came up with involved the direct application of BCD with modifications of our own to suit this application. BCD relies on <a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" target="_blank" rel="external">expectation-maximization</a> algorithm applied on the <a href="https://en.wikipedia.org/wiki/Color_triangle" target="_blank" rel="external">Maxwellian triangle</a>. Hence, the first step was to convert the RGB image of captured by the camera to its Maxwellian triangle.</p>
<p><img src="/images/LaneDet7.jpg" alt="maxwell triangle"></p>
<p>Since the expectation maximization initialises its parameter estimates by using k-means on the data and then improves the  estimates  using  an  iterative  process, it is more robust compared to methods based on segmentation using k-means. When  we  run it on a video stream obtained from the camera, we use estimates obtained from  the previous frame as initial estimates for the next frame. Thus, it saves processing time as k-means need not be applied on each frame. For the first frame, the prior is the initial supervision provided to the autonomous system about the road. This method  also  addresses  the  problems  of  gradually changing road conditions using a constant adaptation of the prior  knowledge. With every iteration, we update the prior knowledge to move towards the present centroid of the road cluster detected. The rate  of  movement  is  controlled  using  a  learning  rate.</p>
<p>Segmentation output:<br><img src="/images/LaneDet5.jpg" alt="seg output"></p>
<p>After  the  road/lanes  are  segmented  from  the  rest  of  the image,  the  next  step  of  the  algorithm  is  to  interpolate  the data to form continuous outputs - the edges of the road and the lanes respectively.</p>
<p><img src="/images/LaneDet6.jpg" alt="spline ouput"></p>
<h3 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h3><p>I recently began experimenting with lane detection using CNNs, mostly because I could overcome my laziness of annotating the ground truth by the availability of a dataset online. The data consists of about 8000 images of size 1200x1200 with the ground truth of the same size. Now, most GPUs today do not have sufficient memory to train a CNN with images of that large a size. So, I first broke down each image into 32x32 windows. After this point, I have tried various approaches but with limited success:</p>
<ol>
<li>Use a 3-layer convolutional network (convolution-relu-pool) followed by a two layer fully connected network which is again reshaped to 32x32. I framed this as a <strong>regression</strong> problem with L2 (euclidean) loss. </li>
<li>Use the same network as above but frame the problem as a <strong>classification</strong> one (lane vs non-lane binary classification). The loss used was softmax. This gave better results than the previous approach but not close to the ones obtained through SVM and BCD.</li>
<li>Use the same convolutional network as above, but replace the fully connected layers by deconvolutional layers as use in <a href="https://arxiv.org/pdf/1411.4038.pdf" target="_blank" rel="external">fully convolutional networks</a>. This is a <strong>semantic segmentation</strong> problem. I haven’t incorporated the <em>skip-layers</em> yet and the output, thus, was very coarse. </li>
</ol>
<p>The original image:<br><img src="/images/LaneDet3.jpg" alt="x"></p>
<p>The ground truth:<br><img src="/images/LaneDet4.jpg" alt="y_true"></p>
<p>The output of regression network:<br><img src="/images/LaneDet2.jpg" alt="y_pred"> </p>
<p>So far, these three approaches <strong>clearly</strong> haven’t been able to improve the existing methods I described above, but I am still working on these and will post updates soon (right now, I am busy with a project on depth-regression - more on that later). However, the interesting takeaway from these experiments is how a single problem, in this case -  lane detection, could be framed as a regression, classification, as well as a semantic segmentation problem!</p>


            <!-- Tags -->
            


<div class="tags">
    
</div>



            <!-- Comments -->
            <div>
                


            </div>
        </div><!-- end content -->
    </section>
</section><!-- end main -->

<!-- After footer scripts -->

<!-- jQuery -->
<script src="/js/jquery.js"></script>

<!-- Custom Code -->
<script src="/js/main.js"></script>

<!-- Gallery -->
<script src="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->


</body>

</html>