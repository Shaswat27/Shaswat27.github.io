<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0" />

    <!--Description-->
    
        <meta name="description" content="Personal blog and porfolio page">
    

    <!--Author-->
    
        <meta name="author" content="Shaswat Datta">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Visual Odometry"/>
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="Shaswat Datta"/>

    <!--Page Cover-->
    
        <meta property="og:image" content="undefined"/>
    

    <!-- Title -->
    
    <title>Visual Odometry - Shaswat Datta</title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/reset.css">
    <link rel="stylesheet" href="/css/main.css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-83741901-1', 'auto');
        ga('send', 'pageview');

    </script>



</head>

<body>

<!-- Menu -->
<!-- Navigation -->
<header>
    <div class="logo">
        <a href="/">Shaswat Datta</a>
    </div><!-- end logo -->

    <div id="menu_icon"></div>
    <nav>
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/archives">Archives</a>
            </li>
            
            <li>
                <a href="/about">About</a>
            </li>
            
        </ul>
    </nav><!-- end navigation menu -->

    <div class="footer clearfix">
        <ul class="social clearfix">
            
            
                <li><a href="https://www.facebook.com/shaswat27" class="fb" target="_blank" data-title="Facebook"></a></li>
            
            
            
                <li><a href="https://in.linkedin.com/in/shaswat-datta-86812075" class="google" target="_blank" data-title="LinkedIn"></a></li>
            
            
                <li><a href="mailto:shaswat.datta@gmail.com" class="dribble" target="_blank" data-title="Email"></a></li>
            
            
                <li><a href="https://www.github.com/shaswat27" class="rss" target="_blank" data-title="Github"></a></li>
            
        </ul><!-- end social -->

        <div class="rights">
            <p></p>
            <p></p>
            <p>Copyright © Shaswat Datta.</p>
        </div><!-- end rights -->
    </div ><!-- end footer -->
</header><!-- end header -->


<!-- Main Content -->
<section class="main clearfix">

    <section class="top" style="background: url('/images/VO1.jpg');">
        <div class="wrapper content_header clearfix">
            

<div class="work_nav">

    <ul class="btn clearfix">
        
        <li><a href="/2016/10/21/Laser-Rangefinder/" class="previous" data-title="Laser Rangefinder"></a></li>
        
        <li><a href="/" class="grid" data-title="Portfolio"></a></li>
        
        <li><a href="/2016/10/21/Robot-Motion-Planning/" class="next" data-title="Robot Motion Plan..."></a></li>
        
    </ul>

</div><!-- end work_nav -->
            <h1 class="title">Visual Odometry</h1>
        </div>
    </section><!-- end top -->

    <section class="wrapper">
        <div class="content">

            <!-- Gallery -->
            

            <!-- Content -->
            <p>Odometry in robotics is a general term which refers to estimating not only the distance traveled but the entire trajectory of a moving robot. So, for every instance of time, there is a vector which describes the complete pose of the robot at that instance. There are numerous ways to determine the trajectory of a moving robot. One those is visual odometry. In this approach, the images from a camera (or an array of cameras) rigidly attached to a moving object (such as a car or a robot) are used to construct a 6-DOF trajectory. When using just one camera, it is called monocular visual odometry. This idea of using just the camera to figure out the trajectory of a robot is not only applicable to robotics but also for augmented and virtual reality applications where a trajectory of the user must be generated. </p>
<p>Based on the concepts of visual odometry, I, along with a final year student Vikram, decided to come up with an android app which can be used recreate the trajectory of the user based on the input video feed and allow the user take panoramas at any desired location in real-time. With the hence given motion between the captured images, this will enable the virtual walkthrough mechanism. Such type of navigation would also be useful in unknown environments for mobile robots with cameras mounted on them and hence would also have applications at the <a href="agv-iit-kgp.github.io">Autonomous Ground Vehicle</a> research group we are both a part of. </p>
<p>I created a very basic UI for the android app (being a novice in this aspect) and used the java code mostly for acquiring the data from the camera and storing the images in the memory of the android device. The real <em>action</em> was achieved by the C++ code in which the actual algorithm for visual odometry was coded in and the communication between these parts of the project was achieved by creating a java wrapper for the C++ code using JNI and the android NDK. The algorithm used can be briefly described as follows:</p>
<ol>
<li><strong>Acquire input images</strong> from the android camera and transfer them to the native C++ code through JNI. <em>At this stage, a very important fact that I noticed after debugging a segmentation fault in code for about two hours was that while OpenCV and indeed most other image processing libraries assume the images to be in RGB format by default, the android camera communicates RGB-alpha four channel images</em>. These needed to be converted to RGB. </li>
<li>Apply <strong>image correction</strong> by lens distortion removal and noise removal.</li>
<li><strong>Feature detection</strong>: We used corners in the image for this purpose and the detector of choice was <a href="https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test" target="_blank" rel="external">FAST</a> (Features from Accelerated Segment Test), mainly due to its speed (as the name suggests). At each step 2000 corner points were tracked in the images for better accuracy. <img src="/images/VO2.jpg" alt="FAST"></li>
<li><strong>Feature tracking</strong>: We tracked the corners detected by the above method to the next frame using the <a href="https://en.wikipedia.org/wiki/Kanade%E2%80%93Lucas%E2%80%93Tomasi_feature_tracker" target="_blank" rel="external">Kanade–Lucas–Tomasi</a> (KLT) feature tracker and the optical flow field was thus detected. <img src="/images/VO3.jpg" alt="KLT"></li>
<li>Check flow field vectors for potential tracking errors and remove outliers using <a href="https://en.wikipedia.org/wiki/Random_sample_consensus" target="_blank" rel="external">RANSAC</a> (RANdom SAmple Consensus).</li>
<li>Estimate the <a href="https://en.wikipedia.org/wiki/Essential_matrix" target="_blank" rel="external"><strong>essential matrix</strong></a> between the image pair and recover the rotation and translation matrices using <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.1518&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">Nister’s 5-point algoritm</a>. <em>Note that this process yields at most 4 solutions of rotation and translation</em>. The solution which is in front of the focal plane is selected using the <a href="https://www.researchgate.net/publication/3906082_Cheirality_in_epipolar_geometry" target="_blank" rel="external">cheirality check</a>.</li>
<li>Publish the estimated translation and rotation back to the android code using JNI to be displayed to the user.</li>
</ol>
<p>The app we created is demonstrated in this video take at IIT Kharagpur’s Central Library on my Moto E 2nd Generation (hence, the slow processing) running Android 5.1 (I apologize for poor quality of the video):</p>
<p><div align="center" class="video-container"><iframe width="854" height="480" src="https://www.youtube.com/embed/X45c-vMib5I" frameborder="0" allowfullscreen></iframe></div><br>The implementation of panorama creation used standard stitching techiniques built into OpenCV.</p>


            <!-- Tags -->
            


<div class="tags">
    
</div>



            <!-- Comments -->
            <div>
                


            </div>
        </div><!-- end content -->
    </section>
</section><!-- end main -->

<!-- After footer scripts -->

<!-- jQuery -->
<script src="/js/jquery.js"></script>

<!-- Custom Code -->
<script src="/js/main.js"></script>

<!-- Gallery -->
<script src="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->


</body>

</html>